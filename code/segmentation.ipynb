{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b087e860",
   "metadata": {},
   "source": [
    "## SEGMENTATION\n",
    "\n",
    "| **Step**                 | **Otsu Thresholding**                                             | **Active Contours**                                                      | **U-Net (Deep Learning)**                                                             |\n",
    "| ------------------------ | ----------------------------------------------------------------- | ------------------------------------------------------------------------ | ------------------------------------------------------------------------------------- |\n",
    "| **Initial Segmentation** | Global Otsu thresholding to binarize image                        | Evolve contour using Chan-Vese or morphological snakes from initial mask | Input image into trained U-Net to get breast mask                                     |\n",
    "| **Pectoral Removal**     | Manual triangle masking or line detection (Hough)                 | Naturally excluded if contour initialized properly (top-left corner)     | Automatically learned during training (requires labeled data with no pectoral muscle) |\n",
    "| **Postprocessing**       | - Fill holes<br>- Morph ops (open/close)<br>- Keep largest region | - Smooth final contour<br>- Apply contour as mask                        | - Minimal<br>- Optional morphological cleanup                                         |\n",
    "| **Output**               | Binary mask with breast region                                    | Binary mask from active contour                                          | Binary mask from model prediction                                                     |\n",
    "| **Advantages**           | Fast, simple, no training needed                                  | Good edge adherence, flexible, no training                               | Highest accuracy, robust to variation                                                 |\n",
    "| **Limitations**          | Sensitive to noise, may include pectoral or miss weak tissue      | Needs proper initialization, slower                                      | Requires labeled data and training, heavier computational load                        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c28c152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS I CONSTANTS GLOBALS\n",
    "# =============================================================================\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import threshold_multiotsu\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "from skimage.filters import gabor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "from model.unet_model import UNet\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Tuple, Dict, List, Callable\n",
    "\n",
    "# CONSTANTS GLOBALS\n",
    "BASE_PATH: str = \"../data/test\"\n",
    "INPUT_FOLDER_PATHS: str = f\"{BASE_PATH}/inputs/\"\n",
    "MASK_PATHS: Dict[str, str] = {\n",
    "    'otsu': f\"{BASE_PATH}/masks/otsu\",\n",
    "    'kmeans': f\"{BASE_PATH}/masks/kmeans\",\n",
    "    'unet': f\"{BASE_PATH}/masks/unet\"\n",
    "}\n",
    "\n",
    "MODEL_PATH: str = \"model/best_unet.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfac8e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FUNCIONS PLANTILLA SIMPLES PER A SEGMENTACIÓ\n",
    "# =============================================================================\n",
    "\n",
    "def largest_connected_component(mask: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Troba i retorna el component connectat més gran de la màscara.\n",
    "    \n",
    "    Args:\n",
    "        mask: Màscara binària d'entrada\n",
    "        \n",
    "    Returns:\n",
    "        Màscara amb només el component connectat més gran\n",
    "    \"\"\"\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask)\n",
    "    if num_labels <= 1:\n",
    "        return mask\n",
    "    largest: int = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])\n",
    "    return (labels == largest).astype(np.uint8) * 255  # 0/255\n",
    "\n",
    "\n",
    "def process_mask(mask: np.ndarray, open: int, close: int, size_k: int, lcc: bool = True) -> np.ndarray:\n",
    "    \"\"\"Processa una màscara amb operacions morfològiques.\n",
    "    \n",
    "    Args:\n",
    "        mask: Màscara d'entrada\n",
    "        open: Nombre d'iteracions d'obertura\n",
    "        close: Nombre d'iteracions de tancament\n",
    "        size_k: Mida del kernel morfològic\n",
    "        lcc: Si cal mantenir només el component connectat més gran\n",
    "        \n",
    "    Returns:\n",
    "        Màscara processada\n",
    "    \"\"\"\n",
    "    kernel: np.ndarray = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (size_k, size_k))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=open) \n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=close)\n",
    "    if lcc: \n",
    "        mask = largest_connected_component(mask)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def segmentation_otsu(imatge: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Segmenta una imatge en escala de grisos mitjançant Multi-Otsu, selecciona regions d'interès,\n",
    "    omple concavitats grans i forats (fins i tot els que toquen la vora) i retorna la imatge segmentada\n",
    "    i la màscara final suavitzada.\n",
    "    \n",
    "    Args:\n",
    "        imatge: Imatge en escala de grisos\n",
    "        \n",
    "    Returns:\n",
    "        Tupla amb (imatge_segmentada, màscara_pit)\n",
    "    \"\"\"\n",
    "\n",
    "    # Multi-Otsu (4 classes)\n",
    "    thresholds: np.ndarray = threshold_multiotsu(imatge, classes=4)\n",
    "    regions: np.ndarray = np.digitize(imatge, bins=thresholds)\n",
    "    \n",
    "\n",
    "    # Selecció de classes rellevants (teixit fibrós i greix)\n",
    "    fib_mask: np.ndarray = (regions == 1).astype(np.uint8) * 255\n",
    "    fat_mask: np.ndarray = (regions == 2).astype(np.uint8) * 255\n",
    "\n",
    "    # Fusió i neteja\n",
    "    breast_mask: np.ndarray = cv2.bitwise_or(fib_mask, fat_mask)\n",
    "    breast_mask = largest_connected_component(breast_mask)\n",
    "\n",
    "    # Omplir forats interns (tancats i oberts a les vores)\n",
    "    breast_mask = binary_fill_holes(breast_mask > 0).astype(np.uint8) * 255\n",
    "    breast_mask = process_mask(breast_mask, open=1, close=3, size_k=5)\n",
    "\n",
    "    # Suavitzar contorn\n",
    "    breast_mask = cv2.GaussianBlur(breast_mask, (15, 15), 7)\n",
    "    breast_mask = cv2.threshold(breast_mask, 120, 255, cv2.THRESH_BINARY)[1]\n",
    "    breast_mask = binary_fill_holes(breast_mask > 0).astype(np.uint8) * 255\n",
    "\n",
    "    # Aplicació de la màscara a la imatge original\n",
    "    imatge_segmentada: np.ndarray = cv2.bitwise_and(imatge, imatge, mask=breast_mask)\n",
    "\n",
    "    return imatge_segmentada, breast_mask\n",
    "\n",
    "\n",
    "def segmentation_kmeans(imatge: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Segmenta una imatge utilitzant K-means clustering amb intensitat i textura Gabor (reduïda amb PCA).\n",
    "    \n",
    "    Args:\n",
    "        imatge: Imatge en escala de grisos\n",
    "        \n",
    "    Returns:\n",
    "        Tupla amb (imatge_segmentada, màscara_pit)\n",
    "    \"\"\"\n",
    "\n",
    "    imatge_mod: np.ndarray = imatge.astype(np.float32)\n",
    "    shape = imatge.shape\n",
    "\n",
    "    def gabor_features(img: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Extreu textura amb diversos filtres Gabor i redueix amb PCA a una sola característica.\n",
    "        \"\"\"\n",
    "        frequencies = [0.5, 0.6, 0.7, 0.8, 9.0, 1.0]\n",
    "        thetas = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "\n",
    "        feature_list = []\n",
    "        for freq in frequencies:\n",
    "            for theta in thetas:\n",
    "                response, _ = gabor(img, frequency=freq, theta=theta)\n",
    "                feature_list.append(response.reshape(-1, 1))  # (n_pixels, 1)\n",
    "\n",
    "        all_features = np.concatenate(feature_list, axis=1)  # (n_pixels, n_features)\n",
    " \n",
    "        # Normalització i Reducció a 1 sola característica\n",
    "        scaled = StandardScaler().fit_transform(all_features)\n",
    "        texture_reduced = PCA(n_components=1).fit_transform(scaled)  # (n_pixels, 1)\n",
    "\n",
    "        return texture_reduced\n",
    "\n",
    "    # 1. Extreure intensitat i textura\n",
    "    intensity = imatge_mod.reshape(-1, 1)\n",
    "    texture = gabor_features(imatge_mod)\n",
    "\n",
    "    # 2. Combinar\n",
    "    features = np.concatenate([intensity, texture], axis=1)\n",
    "    features_scaled = StandardScaler().fit_transform(features)\n",
    "\n",
    "    # 3. K-means clustering\n",
    "    K = 4\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    _, labels, _ = cv2.kmeans(features_scaled.astype(np.float32), K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    labels = labels.flatten()\n",
    "    clustered_image = labels.reshape(shape)\n",
    "\n",
    "    # 4. Classificació de clusters\n",
    "    mean_intensities = [np.mean(intensity[labels == k]) for k in range(K)]\n",
    "    sorted_clusters = np.argsort(mean_intensities)\n",
    "    tissue_clusters = {sorted_clusters[1], sorted_clusters[2]}  # entre fons i pectoral\n",
    "\n",
    "    # 5. Màscara del pit\n",
    "    breast_mask = np.isin(clustered_image, list(tissue_clusters)).astype(np.uint8) * 255\n",
    "    breast_mask = process_mask(breast_mask, open=1, close=3, size_k=5, lcc=True)\n",
    "    breast_mask = binary_fill_holes(breast_mask > 0).astype(np.uint8) * 255\n",
    "\n",
    "    # 7. Segmentació final\n",
    "    imatge_segmentada = cv2.bitwise_and(imatge, imatge, mask=breast_mask)\n",
    "\n",
    "    return imatge_segmentada, breast_mask\n",
    "\n",
    "\n",
    "\n",
    "def segmentation_unet(imatge: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Segmentació simple amb U-Net (simulació).\n",
    "    Basat en: Entrada al model entrenat -> Predicció directa -> Postprocessament mínim\n",
    "    \n",
    "    Args:\n",
    "        imatge: Imatge en escala de grisos\n",
    "        \n",
    "    Returns:\n",
    "        Tupla amb (imatge_segmentada, màscara_pit)\n",
    "    \"\"\"\n",
    "    input_size: Tuple[int, int] = (768, 512)  # (amplada, alçada)\n",
    "\n",
    "    # ---------- Carregar Model ----------\n",
    "    device: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model: UNet = UNet().to(device)\n",
    "    model.load_state_dict(torch.load(Path(MODEL_PATH), map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    # Convertir imatge a float32 i normalitzar a [0, 1]\n",
    "    img_float: np.ndarray = imatge.astype(np.float32) / 255.0\n",
    "    tensor: torch.Tensor = torch.tensor(img_float).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred: torch.Tensor = model(tensor)\n",
    "        breast_mask: np.ndarray = (pred.squeeze().cpu().numpy() > 0.5).astype(np.uint8) * 255\n",
    "\n",
    "    breast_mask = process_mask(breast_mask, open=1, close=2, size_k=10, lcc=True)\n",
    "    imatge_segmentada: np.ndarray = cv2.bitwise_and(imatge, imatge, mask=breast_mask)\n",
    "\n",
    "    return imatge_segmentada, breast_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "168b6a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processant imatges a ..\\data\\test\\inputs utilitzant el mètode 'unet'...\n",
      "✓ Original_1_b1_pib.tiff\n",
      "✓ Original_1_b2_pib.tiff\n",
      "✓ Original_1_b3_pib.tiff\n",
      "✓ Original_1_b4_pib.tiff\n"
     ]
    }
   ],
   "source": [
    "def process_all_images(input_folder: str, method: str = 'otsu') -> None:\n",
    "    \"\"\"Processa totes les imatges d'una carpeta d'entrada i les desa en una carpeta de sortida.\n",
    "    \n",
    "    Args:\n",
    "        input_folder: Ruta de la carpeta d'entrada amb imatges\n",
    "        method: Mètode de segmentació ('otsu', 'kmeans', 'unet')\n",
    "    \"\"\"\n",
    "    input_path: Path = Path(input_folder)\n",
    "    output_path: Path = Path(MASK_PATHS[method])\n",
    "\n",
    "    segmentation_function: Dict[str, Callable[[np.ndarray], Tuple[np.ndarray, np.ndarray]]] = {\n",
    "        'otsu': segmentation_otsu,\n",
    "        'kmeans': segmentation_kmeans,\n",
    "        'unet': segmentation_unet\n",
    "    }\n",
    "\n",
    "    print(f\"Processant imatges a {input_path} utilitzant el mètode '{method}'...\")\n",
    "\n",
    "    for img_file in input_path.glob(\"*\"):\n",
    "        if img_file.suffix.lower() not in {\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\", \".bmp\"}:\n",
    "            continue\n",
    "        image: np.ndarray = cv2.imread(str(img_file), cv2.IMREAD_GRAYSCALE)\n",
    "        if image is None:\n",
    "            print(f\"❌ {img_file.name}\")\n",
    "            continue\n",
    "        imatge_retallada: np.ndarray\n",
    "        breast_mask: np.ndarray\n",
    "        imatge_retallada, breast_mask = segmentation_function[method](image)\n",
    "        \n",
    "        save_path_img: Path = output_path / f\"{img_file.stem}_img.tiff\"\n",
    "        save_path_msk: Path = output_path / f\"{img_file.stem}_msk.tiff\"\n",
    "        cv2.imwrite(str(save_path_img), imatge_retallada)\n",
    "        cv2.imwrite(str(save_path_msk), breast_mask)\n",
    "        print(f\"✓ {img_file.name}\")\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"Funció principal que executa el processament d'imatges.\"\"\"\n",
    "    if not Path(INPUT_FOLDER_PATHS).exists():\n",
    "        print(\"❌ Carpeta no trobada. \")\n",
    "        Path(INPUT_FOLDER_PATHS).mkdir(parents=True)\n",
    "        return\n",
    "\n",
    "    # otsu, kmeans, unet are the methods available\n",
    "    process_all_images(INPUT_FOLDER_PATHS, method='unet')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
