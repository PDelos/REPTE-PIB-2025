# REPTE-PIB: Repte de SegmentaciÃ³ MamogrÃ fica de la Mama

## ğŸ“‹ VisiÃ³ General

Aquest repositori contÃ© una soluciÃ³ integral per a la segmentaciÃ³ mamogrÃ fica de la mama utilitzant mÃºltiples enfocaments, incloent tÃ¨cniques tradicionals de processament d'imatges i aprenentatge profund amb arquitectura U-Net. El projecte implementa pipelines de preprocessament i diversos mÃ¨todes de segmentaciÃ³ per extreure regions de teixit mamari d'imatges mamogrÃ fiques.

## ğŸ¯ Objectius del Projecte

- **Preprocessament**: Implementar un pipeline robust de preprocessament per a imatges mamogrÃ fiques
- **SegmentaciÃ³**: Comparar mÃºltiples enfocaments de segmentaciÃ³ (llindaritzaciÃ³ d'Otsu, agrupament K-means, U-Net)
- **AvaluaciÃ³**: Avaluar el rendiment dels diferents mÃ¨todes de segmentaciÃ³
- **AutomatitzaciÃ³**: Proporcionar un pipeline complet per a la segmentaciÃ³ mamogrÃ fica de la mama

## ğŸ“ Estructura del Repositori

```
REPTE-PIB/
â”œâ”€â”€ README.md                   # DocumentaciÃ³ del projecte
â”œâ”€â”€ requirements.txt            # DependÃ¨ncies de Python
â”œâ”€â”€ Repte.pdf                   # EspecificaciÃ³ del projecte
â”œâ”€â”€ figures/                    # Conjunt de figures pel projecte
â”œâ”€â”€ code/                       # Codi font
â”‚   â”œâ”€â”€ preprocessat.ipynb      # Pipeline de preprocessament d'imatges
â”‚   â”œâ”€â”€ segmentation.ipynb      # ComparaciÃ³ de mÃ¨todes de segmentaciÃ³
â”‚   â””â”€â”€ model/                  # ImplementaciÃ³ U-Net
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ unet_model.py       # Arquitectura U-Net
â”‚       â”œâ”€â”€ train_unet.ipynb    # Entrenament del model
â”‚       â”œâ”€â”€ test_unet.ipynb     # InferÃ¨ncia del model
â”‚       â””â”€â”€ best_unet.pth       # Pesos del model pre-entrenat
â””â”€â”€ data/                       # Conjunt de dades
    â”œâ”€â”€ train/                  # Conjunt d'entrenament
    â”‚   â”œâ”€â”€ images/             # Imatges d'entrenament
    â”‚   â”œâ”€â”€ inputs/             # Imatges d'entrenament preprocessades
    â”‚   â””â”€â”€ masks/              # MÃ scares ground truth
    â””â”€â”€ test/                   # Conjunt de test
        â”œâ”€â”€ images/             # Imatges de test
        â”œâ”€â”€ inputs/             # Imatges de test preprocessades
        â””â”€â”€ masks/              # MÃ scares generades per diferents mÃ¨todes
            â”œâ”€â”€ kmeans/         # Resultats de segmentaciÃ³ K-means
            â”œâ”€â”€ otsu/           # Resultats de llindaritzaciÃ³ d'Otsu
            â””â”€â”€ unet/           # Resultats de segmentaciÃ³ U-Net
```

## ğŸ”§ InstalÂ·laciÃ³

### Prerequisits
- Python 3.8+
- Gestor de paquets pip

### ConfiguraciÃ³ de l'Entorn

1. Clona el repositori:
```bash
git clone <url-del-repositori>
cd REPTE-PIB
```

2. Crea un entorn virtual (recomanat):
```bash
python -m venv venv
venv\Scripts\activate  # Windows
# o
source venv/bin/activate  # Linux/Mac
```

3. InstalÂ·la les dependÃ¨ncies:
```bash
pip install -r requirements.txt
```

## ğŸ“š DependÃ¨ncies

El projecte utilitza les segÃ¼ents llibreries principals:

- **Llibreries Principals**:
  - `numpy` - Computacions numÃ¨riques
  - `opencv-python` - VisiÃ³ per computador i processament d'imatges
  - `matplotlib` - VisualitzaciÃ³
  - `scikit-image` - Processament d'imatges avanÃ§at
  - `scikit-learn` - Utilitats d'aprenentatge automÃ tic

- **Aprenentatge Profund**:
  - `torch` - Framework PyTorch
  - `torchvision` - Utilitats de visiÃ³ per computador per a PyTorch

- **Desenvolupament**:
  - `notebook` - Suport per a Jupyter Notebook
  - `ipykernel` - Kernel IPython per a Jupyter

## ğŸš€ Ãšs

### 1. Preprocessament d'Imatges

El pipeline de preprocessament inclou:
- **EliminaciÃ³ de soroll**: EliminaciÃ³ de soroll sal i pebre utilitzant filtratge mediÃ 
- **EliminaciÃ³ d'artefactes**: EliminaciÃ³ d'etiquetes de text i marcadors
- **EstandarditzaciÃ³ d'orientaciÃ³**: Posicionament anatÃ²mic consistent
- **Millora del contrast**: CLAHE (Contrast Limited Adaptive Histogram Equalization)

```python
# Executa el notebook de preprocessament
jupyter notebook code/preprocessat.ipynb
```

### 2. MÃ¨todes de SegmentaciÃ³

S'implementen tres enfocaments de segmentaciÃ³:

#### LlindaritzaciÃ³ d'Otsu
- Enfocament rÃ pid i simple
- TÃ¨cnica de llindaritzaciÃ³ global
- Bo per a imatges d'alt contrast

#### Agrupament K-means
- Enfocament d'agrupament no supervisat
- Separa el teixit del fons
- MÃ¨tode sense parÃ metres

#### Aprenentatge Profund U-Net
- SegmentaciÃ³ semÃ ntica d'Ãºltima generaciÃ³
- Requereix dades d'entrenament
- Enfocament de mÃ xima precisiÃ³

```python
# Executa la comparaciÃ³ de segmentaciÃ³
jupyter notebook code/segmentation.ipynb
```

### 3. Entrenament U-Net

Entrena el model U-Net amb el teu conjunt de dades:

```python
# Entrena el model
jupyter notebook code/model/train_unet.ipynb
```

### 4. InferÃ¨ncia del Model

Genera mÃ scares de segmentaciÃ³ utilitzant la U-Net entrenada:

```python
# Executa la inferÃ¨ncia
jupyter notebook code/model/test_unet.ipynb
```

## ğŸ—ï¸ Arquitectura

### Arquitectura del Model U-Net

La U-Net implementada segueix l'estructura clÃ ssica codificador-decodificador:

- **Codificador**: CamÃ­ de contracciÃ³ amb dobles convolucions i max pooling
- **Coll d'ampolla**: ExtracciÃ³ de caracterÃ­stiques a la resoluciÃ³ mÃ©s baixa
- **Decodificador**: CamÃ­ d'expansiÃ³ amb upsampling i connexions de salt
- **Entrada**: Imatges mamogrÃ fiques en escala de grisos (1 canal)
- **Sortida**: MÃ scares de segmentaciÃ³ binÃ ries (1 canal)

CaracterÃ­stiques clau:
- Canals d'entrada: 1 (escala de grisos)
- Canals de sortida: 1 (mÃ scara binÃ ria)
- Arquitectura: 4 nivells de codificador/decodificador
- Connexions de salt per a la preservaciÃ³ de caracterÃ­stiques
- NormalitzaciÃ³ per lots per a l'estabilitat d'entrenament

## ğŸ“Š Conjunt de Dades

### Dades d'Entrenament
- **Imatges**: 32 imatges mamogrÃ fiques preprocessades
- **Format**: Fitxers PNG (resoluciÃ³ 768x512)
- **MÃ scares**: MÃ scares de segmentaciÃ³ ground truth corresponents
- **Nomenclatura**: ConvenciÃ³ de noms consistent (Original_X_bY_pib.png)

### Dades de Test
- **Imatges**: 4 imatges mamogrÃ fiques de test
- **Format**: Fitxers TIFF i JPG
- **PropÃ²sit**: AvaluaciÃ³ del model i comparaciÃ³ de mÃ¨todes

## ğŸ¯ AvaluaciÃ³ del Rendiment

El projecte compara els mÃ¨todes de segmentaciÃ³ basant-se en:
- **PrecisiÃ³**: PrecisiÃ³ de classificaciÃ³ pÃ­xel a pÃ­xel
- **Coeficient de Dice**: Solapament entre mÃ scares predites i ground truth
- **IoU (Intersection over Union)**: Ãndex de Jaccard per a la qualitat de segmentaciÃ³
- **Temps de Processament**: EficiÃ¨ncia computacional

## ğŸ”¬ Metodologia

### Pipeline de Preprocessament
1. **Filtratge MediÃ **: Eliminar soroll sal i pebre (kernel 3x3)
2. **EliminaciÃ³ d'Artefactes**: 
   - Retalla marges i elimina etiquetes de text
   - Utilitza operacions morfolÃ²giques i inpainting
3. **EstandarditzaciÃ³ d'OrientaciÃ³**: 
   - Detecta la distribuciÃ³ del teixit
   - Gira horitzontalment si cal per consistÃ¨ncia
4. **Millora del Contrast**: 
   - Normalitza el rang d'intensitat [0, 255]
   - Aplica CLAHE per a millora local del contrast

### Enfocaments de SegmentaciÃ³
1. **MÃ¨todes Tradicionals**:
   - LlindaritzaciÃ³ d'Otsu amb post-processament morfolÃ²gic
   - Agrupament K-means per a separaciÃ³ teixit/fons
   
2. **Aprenentatge Profund**:
   - Entrenament U-Net amb conjunt de dades personalitzat
   - AugmentaciÃ³ de dades i divisiÃ³ de validaciÃ³
   - AvaluaciÃ³ del model i inferÃ¨ncia


## ğŸ“„ LlicÃ¨ncia

Aquest projecte estÃ  desenvolupat amb fins acadÃ¨mics. Si us plau, consulta el document d'especificaciÃ³ del projecte (`Repte.pdf`) per obtenir requisits i directrius detallades.

## ğŸ”— ReferÃ¨ncies

- U-Net: Convolutional Networks for Biomedical Image Segmentation
- DocumentaciÃ³ d'OpenCV
- DocumentaciÃ³ de PyTorch
- DocumentaciÃ³ de Scikit-image
